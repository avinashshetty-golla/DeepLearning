{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3e7ac-5428-40a9-b0d3-bcfe31f989c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 2320/2320 [09:02<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Loss: 5.883984201118864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2320/2320 [09:03<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Loss: 5.356978672126244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2320/2320 [09:03<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Loss: 4.911500815687509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  67%|██████▋   | 10585/15875 [01:14<00:37, 139.76it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Load and process data\n",
    "def read_data(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    contexts, questions, answers = [], [], []\n",
    "\n",
    "    for group in data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return contexts, questions, answers\n",
    "\n",
    "def set_answer_boundaries(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        answer['text'] = answer['text'].lower()\n",
    "        answer['end_position'] = answer['answer_start'] + len(answer['text'])\n",
    "\n",
    "# Dataset and tokenization\n",
    "class QuestionAnswerDataset(Dataset):\n",
    "    def __init__(self, encodings, answers):\n",
    "        self.encodings = encodings\n",
    "        self.answers = answers\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['start_positions'] = torch.tensor(self.answers[idx]['answer_start'])\n",
    "        item['end_positions'] = torch.tensor(self.answers[idx]['end_position'])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# Load the training and validation data\n",
    "train_contexts, train_questions, train_answers = read_data('spoken_train-v1.1.json')\n",
    "valid_contexts, valid_questions, valid_answers = read_data('spoken_test-v1.1.json')\n",
    "\n",
    "set_answer_boundaries(train_answers, train_contexts)\n",
    "set_answer_boundaries(valid_answers, valid_contexts)\n",
    "\n",
    "# Model and tokenizer setup\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "MAX_SEQ_LEN = 512\n",
    "DOC_STRIDE = 128\n",
    "\n",
    "train_encodings = tokenizer(train_questions, train_contexts, max_length=MAX_SEQ_LEN, padding='max_length', truncation=True)\n",
    "valid_encodings = tokenizer(valid_questions, valid_contexts, max_length=MAX_SEQ_LEN, padding='max_length', truncation=True)\n",
    "\n",
    "train_data = QuestionAnswerDataset(train_encodings, train_answers)\n",
    "valid_data = QuestionAnswerDataset(valid_encodings, valid_answers)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=1)\n",
    "\n",
    "# Model initialization\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "EPOCHS = 3\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train_step(model, dataloader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc='Training'):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def compute_wer(predicted_text, true_text):\n",
    "    if true_text.strip():\n",
    "        return jiwer.wer(true_text, predicted_text)\n",
    "    return 0.0\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_true_spans = []\n",
    "    all_pred_spans = []\n",
    "    wer_scores = []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc='Evaluating'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        pred_start = torch.argmax(output.start_logits, dim=1)\n",
    "        pred_end = torch.argmax(output.end_logits, dim=1)\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "            predicted_text = tokenizer.decode(input_ids[i][pred_start[i]:pred_end[i]+1])\n",
    "            true_text = tokenizer.decode(input_ids[i][start_positions[i]:end_positions[i]+1])\n",
    "            wer = compute_wer(predicted_text, true_text)\n",
    "            wer_scores.append(wer)\n",
    "\n",
    "            # Token-level F1 score calculation\n",
    "            true_span_tokens = set(tokenizer.encode(true_text, add_special_tokens=False))\n",
    "            pred_span_tokens = set(tokenizer.encode(predicted_text, add_special_tokens=False))\n",
    "            all_true_spans.append(true_span_tokens)\n",
    "            all_pred_spans.append(pred_span_tokens)\n",
    "\n",
    "    avg_wer = sum(wer_scores) / len(wer_scores) if wer_scores else 0.0\n",
    "\n",
    "    # Calculate token-level F1 score across all predictions\n",
    "    all_true_tokens = set().union(*all_true_spans)\n",
    "    all_pred_tokens = set().union(*all_pred_spans)\n",
    "    true_positives = len(all_true_tokens & all_pred_tokens)\n",
    "    precision = true_positives / len(all_pred_tokens) if all_pred_tokens else 0\n",
    "    recall = true_positives / len(all_true_tokens) if all_true_tokens else 0\n",
    "    f1_score_model = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    return avg_wer, f1_score_model\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_train_loss = train_step(model, train_dataloader, optimizer, scheduler)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_train_loss}\")\n",
    "\n",
    "# Final evaluation for the entire model\n",
    "wer, final_f1_score = evaluate(model, valid_dataloader)\n",
    "print(f\"Final Evaluation - WER: {wer}, F1 Score: {final_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d9bf9-9ec0-4432-998c-54364d2ee1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d96936-0414-43cf-a2b1-76b9b9c36efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
