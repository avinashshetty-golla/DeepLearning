{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa28aff5-7c3a-42de-b65e-dec992b8fd28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 2320/2320 [09:02<00:00,  4.28it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [01:56<00:00, 135.79it/s]\n",
      "INFO:__main__:Evaluation - WER: 11.1133, Precision: 0.2998, Recall: 0.7329, F1 Score: 0.3254\n",
      "INFO:__main__:Epoch 1/3, Training Loss: 5.980311680456688, Evaluation - WER: 11.1133\n",
      "Training: 100%|██████████| 2320/2320 [17:03<00:00,  2.27it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [06:07<00:00, 43.22it/s] \n",
      "INFO:__main__:Evaluation - WER: 6.6106, Precision: 0.4313, Recall: 0.6887, F1 Score: 0.4420\n",
      "INFO:__main__:Epoch 2/3, Training Loss: 5.480455759270438, Evaluation - WER: 6.6106\n",
      "Training: 100%|██████████| 2320/2320 [16:17<00:00,  2.37it/s]\n",
      "Evaluating: 100%|██████████| 15875/15875 [06:58<00:00, 37.95it/s]\n",
      "INFO:__main__:Evaluation - WER: 2.1843, Precision: 0.5947, Recall: 0.6357, F1 Score: 0.5765\n",
      "INFO:__main__:Epoch 3/3, Training Loss: 4.973033870294176, Evaluation - WER: 2.1843\n",
      "Evaluating: 100%|██████████| 15875/15875 [06:58<00:00, 37.96it/s]\n",
      "INFO:__main__:Evaluation - WER: 2.1843, Precision: 0.5947, Recall: 0.6357, F1 Score: 0.5765\n",
      "INFO:__main__:Final Evaluation - Precision: 0.5947, Recall: 0.6357, F1 Score: 0.5765\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import jiwer\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# Set device for training\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Function to read data file and parse questions, contexts, and answers\n",
    "def read_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        log.error(f\"Unable to locate the file: {file_path}\")\n",
    "        raise\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    total_questions = 0\n",
    "    possible_count = 0\n",
    "    impossible_count = 0\n",
    "\n",
    "    for section in data[\"data\"]:\n",
    "        for passage in section[\"paragraphs\"]:\n",
    "            context = passage[\"context\"]\n",
    "            for qna in passage[\"qas\"]:\n",
    "                question = qna[\"question\"]\n",
    "                total_questions += 1\n",
    "                if \"is_impossible\" in qna and qna[\"is_impossible\"]:\n",
    "                    impossible_count += 1\n",
    "                else:\n",
    "                    possible_count += 1\n",
    "                for ans in qna.get(\"answers\", []):\n",
    "                    contexts.append(context.lower())\n",
    "                    questions.append(question.lower())\n",
    "                    answers.append(ans)\n",
    "\n",
    "    return total_questions, possible_count, impossible_count, contexts, questions, answers\n",
    "\n",
    "# Load training and validation data\n",
    "try:\n",
    "    train_totals, train_possible, train_impossible, train_texts, train_qs, train_ans = read_data(\"spoken_train-v1.1.json\")\n",
    "    valid_totals, valid_possible, valid_impossible, valid_texts, valid_qs, valid_ans = read_data(\"spoken_test-v1.1.json\")\n",
    "except Exception as err:\n",
    "    log.error(f\"Data loading error: {err}\")\n",
    "    exit()\n",
    "\n",
    "# Function to calculate answer end positions\n",
    "def compute_answer_ends(answers, contexts):\n",
    "    for ans, context in zip(answers, contexts):\n",
    "        answer_txt = ans.get(\"text\", \"\").lower()\n",
    "        answer_start = ans.get(\"answer_start\", -1)\n",
    "        ans[\"answer_end\"] = answer_start + len(answer_txt)\n",
    "\n",
    "compute_answer_ends(train_ans, train_texts)\n",
    "compute_answer_ends(valid_ans, valid_texts)\n",
    "\n",
    "MAX_SEQ_LEN = 512\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Tokenize questions and contexts\n",
    "train_enc = tokenizer(train_qs, train_texts, max_length=MAX_SEQ_LEN, padding=True, truncation=True)\n",
    "valid_enc = tokenizer(valid_qs, valid_texts, max_length=MAX_SEQ_LEN, padding=True, truncation=True)\n",
    "\n",
    "# Custom dataset class\n",
    "class QuestionAnswerDataset(Dataset):\n",
    "    def __init__(self, encodings, answer_data):\n",
    "        self.encodings = encodings\n",
    "        self.answer_data = answer_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"start_pos\"] = torch.tensor(self.answer_data[idx].get(\"answer_start\", -1))\n",
    "        item[\"end_pos\"] = torch.tensor(self.answer_data[idx].get(\"answer_end\", -1))\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# Initialize datasets and loaders\n",
    "train_ds = QuestionAnswerDataset(train_enc, train_ans)\n",
    "valid_ds = QuestionAnswerDataset(valid_enc, valid_ans)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=1)\n",
    "\n",
    "qa_model = DistilBertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n",
    "optim = AdamW(qa_model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training function for one epoch\n",
    "def train_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_epoch_loss = 0.0\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_pos\"].to(device)\n",
    "        end_positions = batch[\"end_pos\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                        start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        total_epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_epoch_loss / len(loader)\n",
    "\n",
    "# Evaluation function with WER and F1 scoring\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    wer_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        true_start = batch[\"start_pos\"].to(device)\n",
    "        true_end = batch[\"end_pos\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        start_preds = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_preds = torch.argmax(outputs.end_logits, dim=1)\n",
    "        \n",
    "        for i in range(len(true_start)):\n",
    "            pred_answer = tokenizer.decode(input_ids[i][start_preds[i]:end_preds[i]+1])\n",
    "            true_answer = tokenizer.decode(input_ids[i][true_start[i]:true_end[i]+1])\n",
    "\n",
    "            if true_answer.strip():\n",
    "                wer_score = jiwer.wer(true_answer, pred_answer)\n",
    "                wer_scores.append(wer_score)\n",
    "\n",
    "                # Calculate F1, precision, and recall for the predicted and actual answer spans\n",
    "                true_tokens = set(tokenizer.encode(true_answer, add_special_tokens=False))\n",
    "                pred_tokens = set(tokenizer.encode(pred_answer, add_special_tokens=False))\n",
    "                \n",
    "                true_positives = len(true_tokens & pred_tokens)\n",
    "                precision = true_positives / len(pred_tokens) if pred_tokens else 0\n",
    "                recall = true_positives / len(true_tokens) if true_tokens else 0\n",
    "                f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "                \n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "                f1_scores.append(f1)\n",
    "\n",
    "    avg_wer = sum(wer_scores) / len(wer_scores) if wer_scores else 0.0\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0.0\n",
    "    avg_precision = sum(precision_scores) / len(precision_scores) if precision_scores else 0.0\n",
    "    avg_recall = sum(recall_scores) / len(recall_scores) if recall_scores else 0.0\n",
    "\n",
    "    log.info(f\"Evaluation - WER: {avg_wer:.4f}, Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F1 Score: {avg_f1:.4f}\")\n",
    "    return avg_wer, avg_precision, avg_recall, avg_f1\n",
    "\n",
    "NUM_EPOCHS = 3  # Reduced from 5 to 3\n",
    "lowest_wer = float(\"inf\")\n",
    "early_stop_patience = 3\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Main training and evaluation loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    avg_train_loss = train_epoch(qa_model, train_dl, optim)\n",
    "    eval_wer, _, _, _ = evaluate(qa_model, valid_dl)  # Ignore F1, precision, recall in per-epoch eval\n",
    "\n",
    "    log.info(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Training Loss: {avg_train_loss}, Evaluation - WER: {eval_wer:.4f}\")\n",
    "\n",
    "    if eval_wer < lowest_wer:\n",
    "        lowest_wer = eval_wer\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            log.info(\"Early stopping initiated.\")\n",
    "            break\n",
    "\n",
    "# Final evaluation after training to get single F1 score\n",
    "_, final_precision, final_recall, final_f1 = evaluate(qa_model, valid_dl)\n",
    "log.info(f\"Final Evaluation - Precision: {final_precision:.4f}, Recall: {final_recall:.4f}, F1 Score: {final_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292ab13-efc6-4cef-b5df-c90ef3b2316b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
